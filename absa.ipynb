{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nicost312/sentiment-analysis-tokopedia?scriptVersionId=185416003\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport numpy as np\nimport pandas as pd\nimport re\n\nfrom datasets import load_from_disk\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n\nfrom sklearn.metrics import f1_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-25T14:37:46.737689Z","iopub.execute_input":"2024-06-25T14:37:46.738565Z","iopub.status.idle":"2024-06-25T14:37:46.744142Z","shell.execute_reply.started":"2024-06-25T14:37:46.738522Z","shell.execute_reply":"2024-06-25T14:37:46.743072Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"indolem/indobert-base-uncased\")\nreview_token = '[REVIEW]'\naspect_token = '[ASPECT]'\nspecial_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\nnum_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)\n\n\ndef clean_text(texts):\n    cleaned_text = []\n    \n    for text in texts:\n        \n        text = text.lower()\n\n        text = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", text) # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n\n        punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n        for p in punctuations:\n            text = text.replace(p,'') #Removing punctuations\n\n        emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n        text = emoji_pattern.sub(r'', text) #Removing emojis\n        cleaned_text.append(text)\n    \n    return cleaned_text\n\n# Preprocess function\ndef preprocess_function(examples):\n    combined_texts = [aspect_token + aspect + review_token + review for aspect, review in zip(examples[\"variable\"], examples[\"review\"])]\n    encoding =  tokenizer(\n        clean_text(examples[\"review\"]), \n        padding=\"max_length\", \n        truncation=True, \n        max_length=128\n    )\n    \n\n    labels_matrix = np.zeros((len(examples['review']), 3))\n    \n    for i, label in enumerate(examples[\"value\"]):\n        labels_matrix[i, int(label)] = 1\n\n        encoding[\"labels\"] = labels_matrix.tolist()\n  \n    return encoding\n\ntrain_df = pd.read_csv('/kaggle/input/bert-absa-dataset/out.csv').iloc[:4612, :]\ntest_df = pd.read_csv('/kaggle/input/bert-absa-dataset/out.csv').iloc[4612:, :]\n\n# Convert your data to Hugging Face Dataset\ntrain_dataset = Dataset.from_pandas(train_df)\ntest_dataset = Dataset.from_pandas(test_df)\n\ntokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\ntokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\n\ntokenized_train_dataset = tokenized_train_dataset.remove_columns([\"review\", \"rating\", \"variable\", \"value\"])\ntokenized_test_dataset = tokenized_test_dataset.remove_columns([\"review\", \"rating\", \"variable\", \"value\"])","metadata":{"execution":{"iopub.status.busy":"2024-06-25T15:48:44.960978Z","iopub.execute_input":"2024-06-25T15:48:44.961813Z","iopub.status.idle":"2024-06-25T15:48:48.116897Z","shell.execute_reply.started":"2024-06-25T15:48:44.961779Z","shell.execute_reply":"2024-06-25T15:48:48.115873Z"},"trusted":true},"execution_count":110,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4612 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6137064a713f4508a0beca882fb332fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1152 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de6782a89fa34f839f58e31115c49c2f"}},"metadata":{}}]},{"cell_type":"code","source":"# Load pre-trained model with a classification head\nmodel = AutoModelForSequenceClassification.from_pretrained(\"indolem/indobert-base-uncased\", num_labels=3)\nmodel.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-06-25T17:03:43.570294Z","iopub.execute_input":"2024-06-25T17:03:43.570765Z","iopub.status.idle":"2024-06-25T17:03:44.536874Z","shell.execute_reply.started":"2024-06-25T17:03:43.570735Z","shell.execute_reply":"2024-06-25T17:03:44.53571Z"},"trusted":true},"execution_count":151,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":151,"output_type":"execute_result","data":{"text/plain":"Embedding(31925, 768)"},"metadata":{}}]},{"cell_type":"code","source":"print(tokenized_train_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-06-25T15:48:52.040681Z","iopub.execute_input":"2024-06-25T15:48:52.041457Z","iopub.status.idle":"2024-06-25T15:48:52.047821Z","shell.execute_reply.started":"2024-06-25T15:48:52.041423Z","shell.execute_reply":"2024-06-25T15:48:52.046679Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n    num_rows: 4612\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\nfrom transformers import EvalPrediction\nimport torch\n    \ndef accuracy_metric(predictions, labels, threshold=0.5):\n    y_true = labels\n    \n#     print(predictions[5])\n    y_pred_indices = np.argmax(predictions, axis=1)\n    y_pred_one_hot = np.zeros_like(predictions)\n    y_pred_one_hot[np.arange(predictions.shape[0]), y_pred_indices] = 1\n    \n#     print(y_true[5])\n#     print(y_pred_one_hot[5])\n    accuracy = accuracy_score(y_true, y_pred_one_hot)\n    # return as dictionary\n    metrics = {'accuracy': accuracy}\n    return metrics\n\ndef compute_metrics(p: EvalPrediction):\n    preds = p.predictions[0] if isinstance(p.predictions, \n            tuple) else p.predictions\n    result = accuracy_metric(\n        predictions=preds, \n        labels=p.label_ids)\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-06-25T17:04:08.404483Z","iopub.execute_input":"2024-06-25T17:04:08.404838Z","iopub.status.idle":"2024-06-25T17:04:08.414718Z","shell.execute_reply.started":"2024-06-25T17:04:08.404809Z","shell.execute_reply":"2024-06-25T17:04:08.413593Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\n# Define training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    load_best_model_at_end=True,\n    weight_decay=0.01,\n)\n\n# Define trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_test_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\n\n# Train the model\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-06-25T17:04:10.07649Z","iopub.execute_input":"2024-06-25T17:04:10.076869Z","iopub.status.idle":"2024-06-25T17:07:58.423648Z","shell.execute_reply.started":"2024-06-25T17:04:10.076839Z","shell.execute_reply":"2024-06-25T17:07:58.42259Z"},"trusted":true},"execution_count":153,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='435' max='435' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [435/435 03:46, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.245022</td>\n      <td>0.850694</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.226535</td>\n      <td>0.865451</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.224724</td>\n      <td>0.864583</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":153,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=435, training_loss=0.23098295365256824, metrics={'train_runtime': 227.0814, 'train_samples_per_second': 60.93, 'train_steps_per_second': 1.916, 'total_flos': 910109311921152.0, 'train_loss': 0.23098295365256824, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"model.save_pretrained(\"indobert-absa-model-final\")","metadata":{"execution":{"iopub.status.busy":"2024-06-25T17:08:23.822171Z","iopub.execute_input":"2024-06-25T17:08:23.822545Z","iopub.status.idle":"2024-06-25T17:08:24.539454Z","shell.execute_reply.started":"2024-06-25T17:08:23.822512Z","shell.execute_reply":"2024-06-25T17:08:24.538313Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"results = trainer.evaluate(tokenized_test_dataset)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-06-25T17:08:01.040243Z","iopub.execute_input":"2024-06-25T17:08:01.041096Z","iopub.status.idle":"2024-06-25T17:08:07.148055Z","shell.execute_reply.started":"2024-06-25T17:08:01.041061Z","shell.execute_reply":"2024-06-25T17:08:07.14707Z"},"trusted":true},"execution_count":154,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [36/36 00:05]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.22472412884235382, 'eval_accuracy': 0.8645833333333334, 'eval_runtime': 6.095, 'eval_samples_per_second': 189.007, 'eval_steps_per_second': 5.906, 'epoch': 3.0}\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\n# Example test sample\ntest_aspect = \"barang\"\ntest_review = \"lumayan\"\n\n# Preprocess the test sample\ndef preprocess_single_sample(aspect, review):\n    combined_texts = aspect_token + aspect + review_token + review\n    print(len(combined_texts))\n    encoding = tokenizer(\n        combined_texts, \n        padding=\"max_length\", \n        truncation=True, \n        max_length=128,\n        return_tensors=\"pt\"\n    )\n    \n    return encoding\n\n# Preprocess the sample\nencoding = preprocess_single_sample(test_aspect, test_review)\n\n# Move inputs to the same device as the model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ninputs = {key: value.to(device) for key, value in encoding.items()}\nmodel.to(device)\n\n# Put model in evaluation mode\nmodel.eval()\n\n# Run inference\nwith torch.no_grad():\n    outputs = model(**inputs)\n\n# Get predicted label\nlogits = outputs.logits\n# print(logits.shape)\npredicted_class_id = torch.argmax(logits, dim=1).item()\n\n# Map class id to label (Assuming 0: Negative, 1: Neutral, 2: Positive)\nlabel_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\npredicted_label = label_map[predicted_class_id]\n\nprint(f\"Aspect: {test_aspect}\")\nprint(f\"Review: {test_review}\")\nprint(f\"Predicted Sentiment: {predicted_label}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-25T17:08:17.833043Z","iopub.execute_input":"2024-06-25T17:08:17.833823Z","iopub.status.idle":"2024-06-25T17:08:17.871069Z","shell.execute_reply.started":"2024-06-25T17:08:17.833792Z","shell.execute_reply":"2024-06-25T17:08:17.870192Z"},"trusted":true},"execution_count":155,"outputs":[{"name":"stdout","text":"29\nAspect: barang\nReview: lumayan\nPredicted Sentiment: Neutral\n","output_type":"stream"}]}]}