{"cells":[{"cell_type":"markdown","metadata":{},"source":["Identitas Kelompok  \n","Nico Samuelson / C14210017  \n","Darrell Cornelius Rivaldo / C14210025  \n","Nicholas Gunawan / C14210099  \n","Michael Adi Pratama / C14210016"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-26T02:53:57.557249Z","iopub.status.busy":"2024-06-26T02:53:57.556494Z","iopub.status.idle":"2024-06-26T02:54:04.852044Z","shell.execute_reply":"2024-06-26T02:54:04.851253Z","shell.execute_reply.started":"2024-06-26T02:53:57.557215Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","\n","import numpy as np\n","import pandas as pd\n","import re\n","\n","from datasets import Dataset\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n","\n","from sklearn.metrics import f1_score"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T02:54:04.854270Z","iopub.status.busy":"2024-06-26T02:54:04.853726Z","iopub.status.idle":"2024-06-26T02:54:04.860051Z","shell.execute_reply":"2024-06-26T02:54:04.859195Z","shell.execute_reply.started":"2024-06-26T02:54:04.854244Z"},"trusted":true},"outputs":[],"source":["seed = 123"]},{"cell_type":"markdown","metadata":{},"source":["# Reading Dataset"]},{"cell_type":"markdown","metadata":{},"source":["membaca data, data dishuffle, kemudian di split menjadi 2 satu untuk data training dan satu untuk data validasi"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T02:54:04.861689Z","iopub.status.busy":"2024-06-26T02:54:04.861329Z","iopub.status.idle":"2024-06-26T02:54:04.926177Z","shell.execute_reply":"2024-06-26T02:54:04.925326Z","shell.execute_reply.started":"2024-06-26T02:54:04.861660Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['review', 'rating', 'pelayanan', 'pengiriman', 'barang', '__index_level_0__'],\n","    num_rows: 2894\n","})"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["dataset = pd.read_csv('/kaggle/input/absa-aspect/aspect.csv')\n","dataset = dataset.sample(frac=1, random_state=seed) # shuffle\n","\n","train_frac = 0.8\n","train_size = int(train_frac * dataset.shape[0])\n","train = Dataset.from_pandas(dataset.iloc[:train_size])\n","val = Dataset.from_pandas(dataset.iloc[train_size:])\n","train"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing Dataset"]},{"cell_type":"markdown","metadata":{},"source":["1. membuat dictionary label2id dan id2label\n","1. melakukan preprocessing dataset\n","    - mengubah semua huruf pada review menjadi lowercase\n","    - menghapus semua tanda baca pada review\n","    - menghapus semua emoji pada review\n","    - tokenize review\n","    - melakukan multi hot encoding pada label"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T02:54:04.929440Z","iopub.status.busy":"2024-06-26T02:54:04.928919Z","iopub.status.idle":"2024-06-26T02:54:05.888625Z","shell.execute_reply":"2024-06-26T02:54:05.887666Z","shell.execute_reply.started":"2024-06-26T02:54:04.929404Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"768639cc5177473ba26a5cad305f774b","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2894 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"436c291352f447a3b649263c3ac4649f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/724 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset({\n","    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","    num_rows: 2894\n","})\n","Dataset({\n","    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n","    num_rows: 724\n","})\n"]}],"source":["# Define the labels and mappings\n","labels = [label for label in dataset.columns if label not in ('review', 'rating', '__index_level_0__')]\n","id2label = {idx: label for idx, label in enumerate(labels)}\n","label2id = {label: idx for idx, label in enumerate(labels)}\n","\n","# Initialize the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n","\n","def clean_text(texts):\n","    cleaned_text = []\n","    \n","    for text in texts:\n","        \n","        text = text.lower()\n","\n","        text = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", text) # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n","\n","        punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n","        for p in punctuations:\n","            text = text.replace(p,'') #Removing punctuations\n","\n","        emoji_pattern = re.compile(\"[\"\n","                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","                               u\"\\U00002702-\\U000027B0\"\n","                               u\"\\U000024C2-\\U0001F251\"\n","                               \"]+\", flags=re.UNICODE)\n","        text = emoji_pattern.sub(r'', text) #Removing emojis\n","        cleaned_text.append(text)\n","    \n","    return cleaned_text\n","\n","# Define the preprocess function\n","def preprocess_data(examples):\n","    # Take a batch of texts\n","    text = clean_text(examples[\"review\"])\n","    # Encode them\n","    encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128)\n","    # Add labels\n","    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n","    # Create numpy array of shape (batch_size, num_labels)\n","    labels_matrix = np.zeros((len(text), len(labels)))\n","    # Fill numpy array\n","    for idx, label in enumerate(labels):\n","        labels_matrix[:, idx] = labels_batch[label]\n","\n","    encoding[\"labels\"] = labels_matrix.tolist()\n","  \n","    return encoding\n","\n","# Process the datasets\n","processed_train = train.map(preprocess_data, batched=True, remove_columns=train.column_names)\n","processed_val = val.map(preprocess_data, batched=True, remove_columns=val.column_names)\n","\n","# Output the shapes of the processed datasets for verification\n","print(processed_train)\n","print(processed_val)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T02:54:05.890473Z","iopub.status.busy":"2024-06-26T02:54:05.890020Z","iopub.status.idle":"2024-06-26T02:54:05.896071Z","shell.execute_reply":"2024-06-26T02:54:05.895241Z","shell.execute_reply.started":"2024-06-26T02:54:05.890438Z"},"trusted":true},"outputs":[],"source":["processed_train.set_format('torch')\n","processed_val.set_format('torch')"]},{"cell_type":"markdown","metadata":{},"source":["# Inisialisasi Model MultilingualBERT"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T02:54:05.898311Z","iopub.status.busy":"2024-06-26T02:54:05.897513Z","iopub.status.idle":"2024-06-26T02:54:06.397341Z","shell.execute_reply":"2024-06-26T02:54:06.396381Z","shell.execute_reply.started":"2024-06-26T02:54:05.898277Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Load pre-trained model with a classification head\n","model = AutoModelForSequenceClassification.from_pretrained(\n","    \"bert-base-multilingual-cased\", \n","    problem_type='multi_label_classification',\n","    num_labels=len(labels),\n","    id2label=id2label,\n","    label2id=label2id\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T02:54:06.399025Z","iopub.status.busy":"2024-06-26T02:54:06.398651Z","iopub.status.idle":"2024-06-26T02:54:06.403850Z","shell.execute_reply":"2024-06-26T02:54:06.402942Z","shell.execute_reply.started":"2024-06-26T02:54:06.398992Z"},"trusted":true},"outputs":[],"source":["batch_size = 8\n","metric_name = \"f1\""]},{"cell_type":"markdown","metadata":{},"source":["Model IndoBERT akan ditrain sebanyak 10 epoch dengan learning rate 0.00002 dan weight decay 0.01. Model terakhir yang akan diambil adalah model pada epoch dengan metric micro F1 tertinggi"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T02:54:06.405302Z","iopub.status.busy":"2024-06-26T02:54:06.405039Z","iopub.status.idle":"2024-06-26T02:54:06.515874Z","shell.execute_reply":"2024-06-26T02:54:06.515105Z","shell.execute_reply.started":"2024-06-26T02:54:06.405280Z"},"trusted":true},"outputs":[],"source":["args = TrainingArguments(\n","    f\"bert-finetuned-aspect-extractor\",\n","    eval_strategy = \"epoch\",\n","    save_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=10,\n","    weight_decay=0.01,\n","    save_total_limit=1,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=metric_name,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["selain nilai micro f1 selama training, micro ROC AUC dan akurasi juga dihitung untuk tiap epochnya terhadap data validasi"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T02:54:06.518260Z","iopub.status.busy":"2024-06-26T02:54:06.517964Z","iopub.status.idle":"2024-06-26T02:54:06.526386Z","shell.execute_reply":"2024-06-26T02:54:06.525453Z","shell.execute_reply.started":"2024-06-26T02:54:06.518237Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n","from transformers import EvalPrediction\n","import torch\n","    \n","# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n","def multi_label_metrics(predictions, labels, threshold=0.5):\n","    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n","    sigmoid = torch.nn.Sigmoid()\n","    probs = sigmoid(torch.Tensor(predictions))\n","    # next, use threshold to turn them into integer predictions\n","    y_pred = np.zeros(probs.shape)\n","    y_pred[np.where(probs >= threshold)] = 1\n","    # finally, compute metrics\n","    y_true = labels\n","    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n","    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n","    accuracy = accuracy_score(y_true, y_pred)\n","    # return as dictionary\n","    metrics = {'f1': f1_micro_average,\n","               'roc_auc': roc_auc,\n","               'accuracy': accuracy}\n","    return metrics\n","\n","def compute_metrics(p: EvalPrediction):\n","    preds = p.predictions[0] if isinstance(p.predictions, \n","            tuple) else p.predictions\n","    result = multi_label_metrics(\n","        predictions=preds, \n","        labels=p.label_ids)\n","    return result"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T02:54:06.528766Z","iopub.status.busy":"2024-06-26T02:54:06.527817Z","iopub.status.idle":"2024-06-26T03:07:14.246949Z","shell.execute_reply":"2024-06-26T03:07:14.245933Z","shell.execute_reply.started":"2024-06-26T02:54:06.528740Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mc14210017\u001b[0m (\u001b[33mtokped_sentiment_analysis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.17.3 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.17.0"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240626_025409-p65c996l</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/tokped_sentiment_analysis/huggingface/runs/p65c996l' target=\"_blank\">bert-finetuned-aspect-extractor</a></strong> to <a href='https://wandb.ai/tokped_sentiment_analysis/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/tokped_sentiment_analysis/huggingface' target=\"_blank\">https://wandb.ai/tokped_sentiment_analysis/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/tokped_sentiment_analysis/huggingface/runs/p65c996l' target=\"_blank\">https://wandb.ai/tokped_sentiment_analysis/huggingface/runs/p65c996l</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1810' max='1810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1810/1810 12:45, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","      <th>Roc Auc</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.317764</td>\n","      <td>0.888981</td>\n","      <td>0.872330</td>\n","      <td>0.711326</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.279974</td>\n","      <td>0.906383</td>\n","      <td>0.897125</td>\n","      <td>0.763812</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.327500</td>\n","      <td>0.272368</td>\n","      <td>0.907127</td>\n","      <td>0.900465</td>\n","      <td>0.784530</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.327500</td>\n","      <td>0.293635</td>\n","      <td>0.903086</td>\n","      <td>0.897178</td>\n","      <td>0.779006</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.327500</td>\n","      <td>0.285104</td>\n","      <td>0.915385</td>\n","      <td>0.907589</td>\n","      <td>0.798343</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.157000</td>\n","      <td>0.336133</td>\n","      <td>0.901961</td>\n","      <td>0.892620</td>\n","      <td>0.770718</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.157000</td>\n","      <td>0.326306</td>\n","      <td>0.903896</td>\n","      <td>0.897376</td>\n","      <td>0.783149</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.157000</td>\n","      <td>0.335926</td>\n","      <td>0.911652</td>\n","      <td>0.903341</td>\n","      <td>0.788674</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.088400</td>\n","      <td>0.345385</td>\n","      <td>0.911904</td>\n","      <td>0.904735</td>\n","      <td>0.787293</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.088400</td>\n","      <td>0.353831</td>\n","      <td>0.912281</td>\n","      <td>0.904441</td>\n","      <td>0.787293</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/plain":["TrainOutput(global_step=1810, training_loss=0.16801249045693414, metrics={'train_runtime': 786.4746, 'train_samples_per_second': 36.797, 'train_steps_per_second': 2.301, 'total_flos': 1903625577262080.0, 'train_loss': 0.16801249045693414, 'epoch': 10.0})"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=processed_train,\n","    eval_dataset=processed_val,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","trainer.train()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T03:08:38.812639Z","iopub.status.busy":"2024-06-26T03:08:38.811634Z","iopub.status.idle":"2024-06-26T03:08:44.288564Z","shell.execute_reply":"2024-06-26T03:08:44.287621Z","shell.execute_reply.started":"2024-06-26T03:08:38.812586Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [46/46 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 0.28510376811027527,\n"," 'eval_f1': 0.9153846153846155,\n"," 'eval_roc_auc': 0.9075891659962455,\n"," 'eval_accuracy': 0.7983425414364641,\n"," 'eval_runtime': 5.4633,\n"," 'eval_samples_per_second': 132.521,\n"," 'eval_steps_per_second': 8.42,\n"," 'epoch': 10.0}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["trainer.evaluate()"]},{"cell_type":"markdown","metadata":{},"source":["Jika melihat nilai micro f1 0.9154 dan akurasi 0.7983 model MultilingualBERT kalah dengan model IndoBERT. Model ini juga kalah tipis (0.0014) dari segi akurasi dengan model Roberta Indo namun dari segi micro f1 lebih unggul 0.0011"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T03:12:01.702410Z","iopub.status.busy":"2024-06-26T03:12:01.702040Z","iopub.status.idle":"2024-06-26T03:12:01.726291Z","shell.execute_reply":"2024-06-26T03:12:01.725412Z","shell.execute_reply.started":"2024-06-26T03:12:01.702382Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['pengiriman']\n"]}],"source":["text = \"proses dan kirim barang lama banget\"\n","\n","encoding = tokenizer(text, return_tensors=\"pt\")\n","encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n","\n","outputs = trainer.model(**encoding)\n","logits = outputs.logits\n","\n","# apply sigmoid + threshold\n","sigmoid = torch.nn.Sigmoid()\n","probs = sigmoid(logits.squeeze().cpu())\n","predictions = np.zeros(probs.shape)\n","predictions[np.where(probs >= 0.5)] = 1\n","# turn predicted id's into actual label names\n","predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n","print(predicted_labels)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-06-26T03:12:42.794457Z","iopub.status.busy":"2024-06-26T03:12:42.793575Z","iopub.status.idle":"2024-06-26T03:12:44.216377Z","shell.execute_reply":"2024-06-26T03:12:44.215310Z","shell.execute_reply.started":"2024-06-26T03:12:42.794426Z"},"trusted":true},"outputs":[],"source":["trainer.model.save_pretrained('multilingualbert-aspect-extractor')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5281262,"sourceId":8785064,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
